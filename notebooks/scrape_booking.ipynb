{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756c05e5",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc07ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff41a86c",
   "metadata": {},
   "source": [
    "# Chargement du top 5 des villes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charger les villes\n",
    "df_top_city = pd.read_csv('../city_data/df_top_5_city.csv')\n",
    "cities = df_top_city['city'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec64b27",
   "metadata": {},
   "source": [
    "# Récupérer le code html pour les 5 villes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbc94e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialiser un user-agent pour les requêtes HTTP\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Cache-Control\": \"max-age=0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraper chaque ville\n",
    "for city in cities:\n",
    "\n",
    "    #Construire l'URL\n",
    "    encoded_city = urllib.parse.quote_plus(city + \", France\")\n",
    "    url = f\"https://www.booking.com/searchresults.html?ss={encoded_city}&order=bayesian_review_score&nflt=ht_id%3D204\"\n",
    "\n",
    "    #Récupérer la page\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    #Sauvegarder le HTML\n",
    "    filename = f\"booking_{city.replace(' ', '_').lower()}.html\"\n",
    "    with open(\"html_data/\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(response.text)\n",
    "\n",
    "    print(f\"HTML sauvegardé: {filename}\")\n",
    "    print(f\"Status de la requête: {response.status_code}\")\n",
    "    \n",
    "    #Pause entre chaque ville\n",
    "    time.sleep(random.uniform(10, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee416468",
   "metadata": {},
   "source": [
    "# Extraire les informations du code html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3884df",
   "metadata": {},
   "source": [
    "## Fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa03013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hotel_info(hotel):\n",
    "    \"\"\"\n",
    "    Extrait les informations d'un hôtel.\n",
    "\n",
    "    Retourne un dictionnaire avec le nom, l'url, la description et la note.\n",
    "    \"\"\"\n",
    "\n",
    "    info = {\n",
    "        \"name\": None,\n",
    "        \"url\": None,\n",
    "        \"description\": None,\n",
    "        \"rating\": None\n",
    "    }\n",
    "\n",
    "    #Nom de l'hôtel\n",
    "    name = hotel.find('div', {\"data-testid\": \"title\"})\n",
    "    if name:\n",
    "        info[\"name\"] = name.get_text(strip=True)\n",
    "\n",
    "    #URL de l'hôtel\n",
    "    link = hotel.find('a', {\"data-testid\": \"title-link\"})\n",
    "    if link and link.get('href'):\n",
    "        info['url'] = link['href']\n",
    "\n",
    "    #Note de l'hôtel\n",
    "    rating = hotel.find('div', {\"data-testid\": \"review-score\"})\n",
    "    if rating:\n",
    "        rating_div = rating.find(\"div\", class_='dff2e52086')\n",
    "        if not rating_div:\n",
    "            #Autre possibilité de classe\n",
    "            rating_div = rating.find('div', class_='f63b14ab7a dff2e52086')\n",
    "        if rating_div:\n",
    "            info['rating'] = rating_div.get_text(strip=True)\n",
    "\n",
    "    #Description de l'hôtel\n",
    "    #La description est dans une div avec la classe 'fff1944c52'\n",
    "    potential_desc = hotel.find_all('div', class_='fff1944c52')\n",
    "    for desc in potential_desc:\n",
    "        text = desc.get_text(strip=True)\n",
    "        #La description est un texte long qui ne contient pas \"Indiquer sur la carte\"\n",
    "        if len(text) > 50 and \"Indiquer sur la carte\" not in text:\n",
    "            info['description'] = text\n",
    "            break\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f934226",
   "metadata": {},
   "source": [
    "## Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste pour stocker les hotels\n",
    "all_hotels = []\n",
    "\n",
    "#Parcourir chaque ville\n",
    "for city in cities:\n",
    "    filename = f\"booking_{city.replace(' ', '_').lower()}.html\"\n",
    "    with open(\"html_data/\" + filename, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    #Parser le HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    #Trouver les hotels\n",
    "    hotels = soup.find_all('div', {\"data-testid\": \"property-card\"})\n",
    "\n",
    "    print(f\"\\n\\n\\nNombre d'hôtels trouvés pour {city}: {len(hotels)}\")\n",
    "\n",
    "    #Extraire les informations des 5 premiers hotels\n",
    "    for i, hotel in enumerate(hotels[:5]):\n",
    "        hotel_info = extract_hotel_info(hotel)\n",
    "        hotel_info['city'] = city\n",
    "        all_hotels.append(hotel_info)\n",
    "        print(f\"Hôtel {i+1}: {hotel_info['name']} - Note: {hotel_info['rating']}\")\n",
    "\n",
    "#Créer un dataframe avec tous les hôtels\n",
    "df_hotels = pd.DataFrame(all_hotels)\n",
    "\n",
    "#Réorganiser les colonnes\n",
    "colonnes = [\"city\", \"name\", \"url\", \"description\", \"rating\"]\n",
    "df_hotels = df_hotels[colonnes]\n",
    "\n",
    "#Sauvegarder en csv\n",
    "df_hotels.to_csv('../hotel_data/booking_hotels.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e22b2f",
   "metadata": {},
   "source": [
    "# Combiner les datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5632b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informations sur toutes les villes\n",
    "df_hotel_meteo = pd.read_csv(\"../city_data/df_city.csv\", index_col=0)\n",
    "\n",
    "#Garder uniquement les villes où il fait le plus beau\n",
    "df_hotel_meteo = df_hotel_meteo.head()\n",
    "\n",
    "#Ajouter les informations météo aux hôtels\n",
    "df_hotel_meteo = df_hotels.merge(df_hotel_meteo, on='city', how='left')\n",
    "\n",
    "#Enregistrer le nouveau dataframe\n",
    "df_hotel_meteo.to_csv('../hotel_data/booking_hotels_meteo.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kayak_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
